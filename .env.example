# OpenAI API 키
OPENAI_API_KEY=sk-xxxx

# OpenAI 기본 설정 (모든 에이전트 공통 기본값)
# 원하는 모델/타임아웃/재시도 정책을 여기에 설정하세요.
OPENAI_MODEL=gpt-5.1
OPENAI_REASONING_EFFORT=          # 추론 모델이면 low/medium/high, 비추론 모델이면 빈칸(미전송)
OPENAI_TEMPERATURE=0.0
OPENAI_TIMEOUT=120
OPENAI_MAX_RETRIES=2

# OpeningAgent 전용 오버라이드 (설정 시 공통값보다 우선)
# 예: OPENING_OPENAI_MODEL=gpt-5.1
OPENING_OPENAI_MODEL=
OPENING_OPENAI_REASONING_EFFORT=  # 추론 모델이면 low/medium/high, 비추론 모델이면 빈칸
OPENING_OPENAI_TEMPERATURE=
OPENING_OPENAI_TIMEOUT=
OPENING_OPENAI_MAX_RETRIES=

# ThemeAgent 전용 오버라이드 (Worker/Refiner 분리)
# Refiner는 단순 문맥교정이므로 더 빠른(저렴한) "채팅 모델"로 분리 설정 가능
# - 모델 id는 계정/프로젝트 권한에 따라 다르니, `client.models.list()`로 접근 가능한 id를 확인하세요.
THEME_WORKER_OPENAI_MODEL=
THEME_WORKER_OPENAI_REASONING_EFFORT=  # 추론 모델이면 low/medium/high, 비추론 모델이면 빈칸
THEME_WORKER_OPENAI_TEMPERATURE=
THEME_WORKER_OPENAI_TIMEOUT=
THEME_WORKER_OPENAI_MAX_RETRIES=

THEME_REFINER_OPENAI_MODEL=
THEME_REFINER_OPENAI_REASONING_EFFORT=  # 추론 모델이면 low/medium/high, 비추론 모델이면 빈칸 (예: instant 모델)
THEME_REFINER_OPENAI_TEMPERATURE=
THEME_REFINER_OPENAI_TIMEOUT=
THEME_REFINER_OPENAI_MAX_RETRIES=

# (호환용) Refiner 호출에만 별도 timeout을 주고 싶을 때 사용
OPENAI_REFINER_TIMEOUT=

# SSO 프로파일 기반 AWS 접근 (aws sso login --profile Admins)
AWS_SDK_LOAD_CONFIG=1
AWS_PROFILE=Admins
AWS_REGION=ap-northeast-2

# 뉴스 데이터 소스
NEWS_TABLE=kubig-YahoofinanceNews
NEWS_BUCKET=kubig-yahoofinancenews

# Tool 출력 크기 제한 (context_length_exceeded 방지)
# - get_news_content의 body를 LLM 입력용으로만 정리/절단합니다(원본 캐시는 로컬에 저장).
# - 0 이하로 두면 절단하지 않습니다.
NEWS_BODY_MAX_CHARS=8000

# LangSmith 추적 설정 (모든 에이전트 공통)
LANGSMITH_TRACING_V2=false            # true/false
LANGSMITH_API_KEY=your-langsmith-api-key
LANGSMITH_PROJECT=opening-agent
# 선택: 전용 엔드포인트
# LANGSMITH_ENDPOINT=https://api.smith.langchain.com
